---
title: "DHS downsampling to Interceptor"
author: "Marlin"
date: '2022-07-11'
output: pdf_document
---

This analysis seeks to answer whether the DHS method is robust when reducing the number of measurements. We do this by running the analysis with the different smoothing on both the original Madison data and the data downsampled to only the days with the 5 sub interceptor measurements.


```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	echo = FALSE
)
```

```{r, load needed packages}
#needed packages
library(DSIWastewater)
library(lubridate)
library(dplyr)
library(tidyr)
library(ggplot2)
library(zoo)
```



```{r get base data}
#Load dhs data from package
data(WasteWater_data, package = "DSIWastewater")

#convert data into the shape used for the regression analysis
Full_data <- WasteWater_data%>%
  buildWasteAnalysisDF()
```


```{r downsampling}
#String name of the 5 Madison interceptors
intercepter <- c("Madison-P2-Central",
                 "Madison-P8-West",
                 "Madison-P11-SW",
                 "Madison-P7-SE",
                 "Madison-P18-NE"
                 )


InterceptorDates_data <- Full_data%>%
  filter(WWTP %in% intercepter)%>%
  pull(date)

#reducing the data just to the Madison measurements
Mad_data <- Full_data%>%
  filter(WWTP == "Madison MSD WWTF")%>%
  mutate(data = "original sampling")

#reducing the Madison data to just the days with the interceptor measurement
Down_Mad_data <- Mad_data%>%
            filter(date %in% InterceptorDates_data)%>%
  mutate(data = "downsampled")


Mad_data <- Mad_data%>%
  filter(date <= max(Down_Mad_data$date),
         date >= min(Down_Mad_data$date))


Full_data%>%
  filter(WWTP %in% intercepter)%>%
  pull(population_served)%>%
  unique()
```

The interceptors where measured on  Monday and Thursday with around 65 total measurements on each of the two days

```{r day of week}
Down_Mad_data%>%
  mutate(Wday = wday(date, label = TRUE))%>%
  group_by(Wday)%>%
  summarize(n = n())
```


```{r data prep}
#add the smoothing with PrepDataSmoothings from DownSamplingFuncs.R
#also combine the Madison data and the downsampled data
source("DownSamplingFuncs.R")
Full_Mad_data <- list(Mad_data, Down_Mad_data)%>%
    lapply(FUN = PrepDataSmoothings)%>%
    bind_rows()


Full_reg_data <- Full_Mad_data%>%
                          buildRegressionEstimateTable(
                            #columns to run on
                               RunOn = 
                                 c("sars_cov2_adj_load_log10",
                                "SevSmooth",
                                "EXP",
                                "Loess"),
                               #split the analysis into two by if 
                               #it was downsampled
                               SplitOn = "data")

```

this is the plot showing the results of the DHS methods. the downsampled results show a similar ability to keep track of the major trend.

```{r data long, fig.width= 16, fig.height = 12}
createRegressionAnalysis_Plot(Full_reg_data, Full_Mad_data, 
                #controls what columns to plot as points
                 PointVal = c( "sars_cov2_adj_load_log10"),
                #control what columns to plot as lines
                 LineVal = c("Loess", "EXP", "SevSmooth"),
                #controls how to facet it
                 FacGridFormula = Method ~ data,
                nbreak = 2)

```

```{r data wide, fig.width= 40, fig.height = 12}
#create plot using dataframe Full_reg_data and Full_Mad_data
createRegressionAnalysis_Plot(Full_reg_data, Full_Mad_data, 
                #controls what columns to plot as points
                 PointVal = c( "sars_cov2_adj_load_log10"),
                #control what columns to plot as lines
                 LineVal = c("Loess", "EXP", "SevSmooth"),
                #controls how to facet it
                 FacGridFormula = data ~ Method,
                IsLong = FALSE,
                nbreak = 2)
```
